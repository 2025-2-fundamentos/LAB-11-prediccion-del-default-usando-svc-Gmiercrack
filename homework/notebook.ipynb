{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ceb6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import librerias \n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d954def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(path):\n",
    "\n",
    "    # Verificación básica de existencia\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"El archivo no existe: {path}\")\n",
    "\n",
    "    with zipfile.ZipFile(path, \"r\") as z:\n",
    "        csv_file = z.namelist()[0]\n",
    "        with z.open(csv_file) as f:\n",
    "            # Optimización: No cargar la columna ID para ahorrar memoria\n",
    "            df = pd.read_csv(f, usecols=lambda col: col != \"ID\")\n",
    "\n",
    "    # Encadenamiento de métodos para limpieza\n",
    "    df = (df\n",
    "          .rename(columns={\"default payment next month\": \"default\"})\n",
    "          .dropna()\n",
    "    )\n",
    "\n",
    "    df[\"EDUCATION\"] = df[\"EDUCATION\"].clip(upper=4)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1da5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(x_train: pd.DataFrame) -> Pipeline:\n",
    "    cat_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "    num_features = [col for col in x_train.columns if col not in cat_features]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(), cat_features),\n",
    "            (\"scaler\", StandardScaler(), num_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"pca\", PCA()),\n",
    "        (\"feature_selection\", SelectKBest(score_func=f_classif)),\n",
    "        (\"classifier\", SVC(kernel=\"rbf\", random_state=12345, max_iter=-1)),\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131787bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(pipeline: Pipeline, x_train: pd.DataFrame) -> GridSearchCV:\n",
    "    param_grid = {\n",
    "        \"pca__n_components\": [20, x_train.shape[1] - 2],\n",
    "        \"feature_selection__k\": [12],\n",
    "        \"classifier__kernel\": [\"rbf\"],\n",
    "        \"classifier__gamma\": [0.1],\n",
    "    }\n",
    "\n",
    "    return GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        n_jobs=-1,\n",
    "        refit=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "710dac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    os.makedirs(\"files/models\", exist_ok=True)\n",
    "    path = \"files/models/model.pkl.gz\"\n",
    "\n",
    "    with gzip.open(path, \"wb\") as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a7b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_metrics(model, X_train, X_test, y_train, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_metrics = {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": \"train\",\n",
    "        \"precision\": precision_score(y_train, y_train_pred, zero_division=0),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_train, y_train_pred),\n",
    "        \"recall\": recall_score(y_train, y_train_pred, zero_division=0),\n",
    "        \"f1_score\": f1_score(y_train, y_train_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "    test_metrics = {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": \"test\",\n",
    "        \"precision\": precision_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_test, y_test_pred),\n",
    "        \"recall\": recall_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_test_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "    os.makedirs(\"../files/output\", exist_ok=True)\n",
    "    output_path = \"../files/output/metrics.json\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(json.dumps(train_metrics) + \"\\n\")\n",
    "        f.write(json.dumps(test_metrics) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29db6c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_confusion_matrices(model, X_train, X_test, y_train, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    def format_cm(cm, dataset):\n",
    "        return {\n",
    "            \"type\": \"cm_matrix\",\n",
    "            \"dataset\": dataset,\n",
    "            \"true_0\": {\n",
    "                \"predicted_0\": int(cm[0, 0]),\n",
    "                \"predicted_1\": int(cm[0, 1]),\n",
    "            },\n",
    "            \"true_1\": {\n",
    "                \"predicted_0\": int(cm[1, 0]),\n",
    "                \"predicted_1\": int(cm[1, 1]),\n",
    "            },\n",
    "        }\n",
    "\n",
    "    metrics = [\n",
    "        format_cm(cm_train, \"train\"),\n",
    "        format_cm(cm_test, \"test\"),\n",
    "    ]\n",
    "\n",
    "    path = \"../files/output/metrics.json\"\n",
    "    with open(path, \"a\") as f:\n",
    "        for m in metrics:\n",
    "            f.write(json.dumps(m) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    TRAIN_PATH = \"./files/input/train_data.csv.zip\"\n",
    "    TEST_PATH = \"./files/input/test_data.csv.zip\"\n",
    "\n",
    "    df_train = clean_dataset(TRAIN_PATH)\n",
    "    df_test = clean_dataset(TEST_PATH)\n",
    "\n",
    "\n",
    "    X_train = df_train.drop(columns=[\"default\"])\n",
    "    y_train = df_train[\"default\"]\n",
    "\n",
    "    X_test = df_test.drop(columns=[\"default\"])\n",
    "    y_test = df_test[\"default\"]\n",
    "\n",
    "    pipeline = create_pipeline(X_train)\n",
    "    model = create_estimator(pipeline, X_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    save_model(model)\n",
    "\n",
    "    calculate_and_save_metrics(model, X_train, X_test, y_train, y_test)\n",
    "    calculate_and_save_confusion_matrices(model, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
